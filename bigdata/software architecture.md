
### 빅데이터

![빅데이터 소프트웨어 아키텍처](https://github.com/ynicekyhh/TIL/blob/master/bigdata/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98.PNG)


### BigData Software Architecture


스마트카 예제.
스마트카 주행로그는 3초마다 데이터를 수집
스마트카 상태로그는 하루에 한 번 수집
(모든 설명은 틀릴 수 있으며, 이해한 바를 바탕으로 작성함)

##### Zookeeper
- 데이터 분산 코디네이터, 하둡 시스템에서 분산되어 있는 데이터들을 예전에는 standBy로 멈춰놓고 동기화를 직접 하나 씩 해 줘야 했었는데, Zookeeper가 동기화 처리를 담당해준다.
- Zookeeper는 직접 사용하는게 아니라, 하둡의 Yarn이나 Kafka가 사용할 수 있도록 해줌

##### Flume
- 플럼은 로그를 수집하는 역할

##### Kafka
- 카프카는 수집된 로그에서 실시간 처리를 할 때, 메세지 큐로 버퍼링을 관리

##### Storm/Esper
- 스톰과 에스퍼는 카프카에서 관리될 때 이벤트 발생을 처리 -> Redis나 HBase로 저장

##### Redis
- 실시간 데이터 처리를 할 때, 속도를 위해 메모리상에서 처리하며(하둡을 거치지 않음) 즉시 서비스/업무 시스템에 적용

##### HBase
- 실시간 데이터 중 필요한 데이터들을 하둡에 저장하는데, 데이터를 디스크에 쓰는 작업은 시간이 걸릴 수 있으니 HBase가 하둡과 연동하여 저장시킴
- NoSQL 로 저장 될 수 있으며 이 때, MongoDB등을 사용할 수 있음

##### Hadoop
- 데이터를 분산하여 저장하게 함(HDFS - 하둡 파일 시스템)
- 기존에는 Map + Reduce를 사용하여 저장하고 가져와 처리하도록 하면서 Java로 MapReduce 를 구현하여 만들었는데, 구현상의 어려움과 성능의 문제로 현재는 스파크 등을 사용

##### Hue
- 웹 어플리케이션으로 SublimeText와 비슷하게 하이브/스파크/우지/스쿱 등을 플러그인처럼 설치 후 웹 상에서 해당 프로그램의 커맨드를 보내어 실행 할 수 있게 하여 관리를 편하게 함

##### Hive/Spark
- Hive는 하둡에서 데이터를 가져올 때 SQL문과 같은 하둡 DB 커맨드를 보내어 DB에서 가져올 수 있음
- Spark는 매번 HDFS에 접근하여 데이터를 가져오면 처리가 느리니까 하둡 데이터의 일정 부분을 메모리로 가져와놓고 거기서 Hive로 원하는 데이터들을 가져오게 하는 역할

##### Oozie
- 처리/탐색 부분의 workflow를 자동화 시켜주는 역할

##### Scoop
- spark등으로 적재된 데이터들을 오라클/MySQL등의 서버 DB로 저장하거나 가져올 때 사용함

##### Impala
- 분석/응용단에서 사용되는 툴로 실시간 분석 엔진이라 할 수 있음

##### Zeppelin
- 하둡에서 가져온 자료들을 Notepad로 보여주는 역할

##### Mahout
- 가져온 데이터들을 활용하여 머신러닝을 함

##### Cloudera
- 위 전체 모든 툴들을 설치하여 연결 테스트를 직접 하려면 너무 복잡하니까, 간단한 설정으로 설치/연결을 담당해주는 툴

##### Yarn
- HDFS 2.0을 사용할 때 사용되는 녀석으로서, Hive로 쿼리문을 날리면 MapReduce형태로 변형시켜 HDFS에서 가져오게 해 주는 역할?
